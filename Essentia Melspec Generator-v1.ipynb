{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate MelSpecs For Essentia from 1.5s Split Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azada\\Anaconda3\\envs\\py37\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "C:\\Users\\azada\\Anaconda3\\envs\\py37\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import scipy \n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_single_audio_to_arr(audio_path, emotion_code, X, Y):\n",
    "    data, sr = librosa.load(audio_path, sr = 48000)\n",
    "    #Make a mel spectrogram from audio\n",
    "    window_width =  0.025 #25 ms  window size \n",
    "    sliding = 0.01 #10ms stride \n",
    "    spec = librosa.feature.melspectrogram(y=data, sr=sr, n_fft = int(window_width*sr), hop_length =int(sliding*sr))\n",
    "    \n",
    "    #Convert amplitude to decibels\n",
    "    db_spec = librosa.power_to_db(spec, ref=np.max)\n",
    "    \n",
    "    to_append = np.reshape(db_spec,(128,-1))\n",
    "    to_append = np.expand_dims(to_append, axis=2) \n",
    "\n",
    "    \n",
    "    #Convert amplitude to decibels\n",
    "    db_spec = librosa.power_to_db(spec, ref=np.max)\n",
    "    X.append(to_append)\n",
    "    Y.append(emotion_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cremad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with: X size:  (8699, 128, 151, 1)  Y size:  (8699,)\n"
     ]
    }
   ],
   "source": [
    "audio_folder_name= r\"data/cremad/Audio1_5WAV\"\n",
    "\n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "\n",
    "curr_file_names = listdir(audio_folder_name)\n",
    "for f in curr_file_names:\n",
    "    if f.endswith('.WAV') or f.endswith('.wav'):\n",
    "        audio_path = join(audio_folder_name,f)\n",
    "        label = f[:5]\n",
    "        convert_single_audio_to_arr(audio_path, label, X, Y)\n",
    "        \n",
    "print(\"Done with: X size: \",np.array(X).shape, \" Y size: \", np.array(Y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y= np.array(Y)\n",
    "np.save(r\"data/cremad/Mel1_5NMP/Mel1_5NMP_X\",X)\n",
    "np.save(r\"data/cremad/Mel1_5NMP/Mel1_5NMP_Y\",Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As plotted array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with: X size:  (8699, 288, 432, 3)  Y size:  (8699,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_folder_name= r\"data/cremad/Audio1_5WAV\"\n",
    "\n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "curr_file_names = listdir(audio_folder_name)\n",
    "for f in curr_file_names:\n",
    "    if f.endswith('.WAV') or f.endswith('.wav'):\n",
    "        audio_path = join(audio_folder_name,f)\n",
    "        label = f[:5]\n",
    "        convert_single_audio_to_plotted_arr(audio_path, label, X, Y, fig)\n",
    "        \n",
    "print(\"Done with: X size: \",np.array(X).shape, \" Y size: \", np.array(Y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "np.save(r\"data/cremad/Mel1_5_PLT_NMP/Mel1_5_PLT_NMP_X\",X)\n",
    "np.save(r\"data/cremad/Mel1_5_PLT_NMP/Mel1_5_PLT_NMP_Y\",Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAVEDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with: X size:  (2915, 128, 151, 1)  Y size:  (2915,)\n"
     ]
    }
   ],
   "source": [
    "audio_folder_name= r\"data/RAVEDESS/Audio1_5WAV\"\n",
    "\n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "\n",
    "curr_file_names = listdir(audio_folder_name)\n",
    "for f in curr_file_names:\n",
    "    if f.endswith('.WAV') or f.endswith('.wav'):\n",
    "        audio_path = join(audio_folder_name,f)\n",
    "        label = f[:5]\n",
    "        convert_single_audio_to_arr(audio_path, label, X, Y)\n",
    "        \n",
    "print(\"Done with: X size: \",np.array(X).shape, \" Y size: \", np.array(Y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y= np.array(Y)\n",
    "np.save(r\"data/RAVEDESS/Ess_Mel_1_5_NMP/Ess_Mel_1_5_NMP_X\",X)\n",
    "np.save(r\"data/RAVEDESS/Ess_Mel_1_5_NMP/Ess_Mel_1_5_NMP_Y\",Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As plotted array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with: X size:  (2915, 288, 432, 3)  Y size:  (2915,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_folder_name= r\"data/RAVEDESS/Audio1_5WAV\"\n",
    "\n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "curr_file_names = listdir(audio_folder_name)\n",
    "for f in curr_file_names:\n",
    "    if f.endswith('.WAV') or f.endswith('.wav'):\n",
    "        audio_path = join(audio_folder_name,f)\n",
    "        label = f[:5]\n",
    "        convert_single_audio_to_plotted_arr(audio_path, label, X, Y, fig)\n",
    "        \n",
    "print(\"Done with: X size: \",np.array(X).shape, \" Y size: \", np.array(Y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "np.save(r\"data/RAVEDESS/Mel1_5_PLT_NMP/Mel1_5_PLT_NMP_X\",X)\n",
    "np.save(r\"data/RAVEDESS/Mel1_5_PLT_NMP/Mel1_5_PLT_NMP_Y\",Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with: X size:  (284, 128, 151, 1)  Y size:  (284,)\n"
     ]
    }
   ],
   "source": [
    "audio_folder_name= r\"data/SAVEE/Audio1_5WAV\"\n",
    "\n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "\n",
    "curr_file_names = listdir(audio_folder_name)\n",
    "for f in curr_file_names:\n",
    "    if f.endswith('.WAV') or f.endswith('.wav'):\n",
    "        audio_path = join(audio_folder_name,f)\n",
    "        label = f[:5]\n",
    "        convert_single_audio_to_arr(audio_path, label, X, Y)\n",
    "        \n",
    "print(\"Done with: X size: \",np.array(X).shape, \" Y size: \", np.array(Y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y= np.array(Y)\n",
    "np.save(r\"data/SAVEE/Mel1_5NMP/Mel1_5NMP_X\",X)\n",
    "np.save(r\"data/SAVEE/Mel1_5NMP/Mel1_5NMP_Y\",Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As plotted array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with: X size:  (284, 288, 432, 3)  Y size:  (284,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_folder_name= r\"data/SAVEE/Audio1_5WAV\"\n",
    "\n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "curr_file_names = listdir(audio_folder_name)\n",
    "for f in curr_file_names:\n",
    "    if f.endswith('.WAV') or f.endswith('.wav'):\n",
    "        audio_path = join(audio_folder_name,f)\n",
    "        label = f[:5]\n",
    "        convert_single_audio_to_plotted_arr(audio_path, label, X, Y, fig)\n",
    "        \n",
    "print(\"Done with: X size: \",np.array(X).shape, \" Y size: \", np.array(Y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "np.save(r\"data/SAVEE/Mel1_5_PLT_NMP/Mel1_5_PLT_NMP_X\",X)\n",
    "np.save(r\"data/SAVEE/Mel1_5_PLT_NMP/Mel1_5_PLT_NMP_Y\",Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with: X size:  (2694, 128, 151, 1)  Y size:  (2694,)\n"
     ]
    }
   ],
   "source": [
    "audio_folder_name= r\"data/TESS/Audio1_5WAV\"\n",
    "\n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "\n",
    "curr_file_names = listdir(audio_folder_name)\n",
    "for f in curr_file_names:\n",
    "    if f.endswith('.WAV') or f.endswith('.wav'):\n",
    "        audio_path = join(audio_folder_name,f)\n",
    "        label = f[:5]\n",
    "        convert_single_audio_to_arr(audio_path, label, X, Y)\n",
    "        \n",
    "print(\"Done with: X size: \",np.array(X).shape, \" Y size: \", np.array(Y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y= np.array(Y)\n",
    "np.save(r\"data/TESS/Mel1_5NMP/Mel1_5NMP_X\",X)\n",
    "np.save(r\"data/TESS/Mel1_5NMP/Mel1_5NMP_Y\",Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As plotted Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with: X size:  (2694, 288, 432, 3)  Y size:  (2694,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_folder_name= r\"data/TESS/Audio1_5WAV\"\n",
    "\n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "curr_file_names = listdir(audio_folder_name)\n",
    "for f in curr_file_names:\n",
    "    if f.endswith('.WAV') or f.endswith('.wav'):\n",
    "        audio_path = join(audio_folder_name,f)\n",
    "        label = f[:5]\n",
    "        convert_single_audio_to_plotted_arr(audio_path, label, X, Y, fig)\n",
    "        \n",
    "print(\"Done with: X size: \",np.array(X).shape, \" Y size: \", np.array(Y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "np.save(r\"data/TESS/Mel1_5_PLT_NMP/Mel1_5_PLT_NMP_X\",X)\n",
    "np.save(r\"data/TESS/Mel1_5_PLT_NMP/Mel1_5_PLT_NMP_Y\",Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
